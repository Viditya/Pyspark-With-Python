{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2aa65084-2564-4b4f-af16-de1d5da5c69d",
   "metadata": {},
   "source": [
    "### Pyspark Part 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "974fbe94-a230-4148-ab99-04536c15ba71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "023cc092-1ebc-4e09-8302-1864a910de35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00b8c100-14c0-4012-9926-8c9c7ccfd592",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/07/31 10:11:25 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/07/31 10:11:26 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('PractiseSpark').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ba62994-3b3b-4b67-8175-d52f26cca7c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://instance-2.asia-south1-a.c.enhanced-bebop-393009.internal:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PractiseSpark</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fc2efe19310>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64679668-4625-4424-8042-e3cd048ebf3e",
   "metadata": {},
   "source": [
    "## Trying different ways of reading data from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a11ead4-fcf2-49b0-9ba6-dddf16ef3020",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_pyspark = spark.read.csv('../test1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "848c92f4-cd85-4ee0-860d-f8e34816ff5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+\n",
      "|      _c0|_c1|       _c2|   _c3|\n",
      "+---------+---+----------+------+\n",
      "|     Name|age|Experience|Salary|\n",
      "|    Krish| 31|        10| 30000|\n",
      "|Sudhanshu| 30|         8| 25000|\n",
      "|    Sunny| 29|         4| 20000|\n",
      "|     Paul| 24|         3| 20000|\n",
      "|   Harsha| 21|         1| 15000|\n",
      "|  Shubham| 23|         2| 18000|\n",
      "+---------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "210b5c04-d511-4e73-a8e9-8dab96c02ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark = spark.read.csv('../test1.csv', header = 'true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5747b6ae-244c-4c25-bccb-4accabfb3d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+\n",
      "|     Name|age|Experience|Salary|\n",
      "+---------+---+----------+------+\n",
      "|    Krish| 31|        10| 30000|\n",
      "|Sudhanshu| 30|         8| 25000|\n",
      "|    Sunny| 29|         4| 20000|\n",
      "|     Paul| 24|         3| 20000|\n",
      "|   Harsha| 21|         1| 15000|\n",
      "|  Shubham| 23|         2| 18000|\n",
      "+---------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2e055b5-51d2-4053-8a53-30797f3db676",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark = spark.read.option('header','true').csv('../test1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c92ce53c-12ab-4380-808b-ab71febb012e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+\n",
      "|     Name|age|Experience|Salary|\n",
      "+---------+---+----------+------+\n",
      "|    Krish| 31|        10| 30000|\n",
      "|Sudhanshu| 30|         8| 25000|\n",
      "|    Sunny| 29|         4| 20000|\n",
      "|     Paul| 24|         3| 20000|\n",
      "|   Harsha| 21|         1| 15000|\n",
      "|  Shubham| 23|         2| 18000|\n",
      "+---------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "56b42de1-705c-4d34-8697-dba5c0148cf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_pyspark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0190b0d9-8533-44f8-848f-eaca0d937e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- age: string (nullable = true)\n",
      " |-- Experience: string (nullable = true)\n",
      " |-- Salary: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9d0c78c3-8c83-4ae9-8e57-c831a9a6acb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark = spark.read.option('header','true').option('inferschema','true').csv('../test1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "abf5e209-7e18-47c7-b2f8-d5ec831d2278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+\n",
      "|     Name|age|Experience|Salary|\n",
      "+---------+---+----------+------+\n",
      "|    Krish| 31|        10| 30000|\n",
      "|Sudhanshu| 30|         8| 25000|\n",
      "|    Sunny| 29|         4| 20000|\n",
      "|     Paul| 24|         3| 20000|\n",
      "|   Harsha| 21|         1| 15000|\n",
      "|  Shubham| 23|         2| 18000|\n",
      "+---------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "869e062d-2e73-43c2-8ad4-2d68289dc08f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- Experience: integer (nullable = true)\n",
      " |-- Salary: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10dd2771-9397-47bf-8ee8-e75498de65fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark = spark.read.csv('../test1.csv', header='true',inferSchema='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6a2849a7-49eb-4f71-a102-f532dbad0ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+\n",
      "|     Name|age|Experience|Salary|\n",
      "+---------+---+----------+------+\n",
      "|    Krish| 31|        10| 30000|\n",
      "|Sudhanshu| 30|         8| 25000|\n",
      "|    Sunny| 29|         4| 20000|\n",
      "|     Paul| 24|         3| 20000|\n",
      "|   Harsha| 21|         1| 15000|\n",
      "|  Shubham| 23|         2| 18000|\n",
      "+---------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ab364436-e60a-43d3-a5d1-88539ffe1ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- Experience: integer (nullable = true)\n",
      " |-- Salary: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5883aaa0-c202-4d11-bc2f-93bedee4900f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_pyspark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6c8a9ba7-095c-4f4e-8e78-73ff7f0361b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Name='Krish', age=31, Experience=10, Salary=30000),\n",
       " Row(Name='Sudhanshu', age=30, Experience=8, Salary=25000),\n",
       " Row(Name='Sunny', age=29, Experience=4, Salary=20000)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57595446-f69a-41fe-8c1e-589dc2a3526b",
   "metadata": {},
   "source": [
    "## Pyspark Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74478ea-72fd-45f9-b06a-9c9eb5febace",
   "metadata": {},
   "source": [
    "### Selecting columns from spark dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0ca16db0-72e0-41a6-888b-47a130b09dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+\n",
      "|     Name|age|\n",
      "+---------+---+\n",
      "|    Krish| 31|\n",
      "|Sudhanshu| 30|\n",
      "|    Sunny| 29|\n",
      "|     Paul| 24|\n",
      "|   Harsha| 21|\n",
      "|  Shubham| 23|\n",
      "+---------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.select(['Name','age']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ddb411be-db25-41d4-ac98-0b102aa7f458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'Experience'>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark['Experience']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "113748ac-af62-4a6e-8628-c9048e0e4829",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Name', 'string'), ('age', 'int'), ('Experience', 'int'), ('Salary', 'int')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2c5ec3a0-b2fc-4c25-bcfd-8c5034d7cf66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/07/31 10:29:40 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "[Stage 15:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------------------+-----------------+------------------+\n",
      "|summary|  Name|               age|       Experience|            Salary|\n",
      "+-------+------+------------------+-----------------+------------------+\n",
      "|  count|     6|                 6|                6|                 6|\n",
      "|   mean|  null|26.333333333333332|4.666666666666667|21333.333333333332|\n",
      "| stddev|  null| 4.179314138308661|3.559026084010437| 5354.126134736337|\n",
      "|    min|Harsha|                21|                1|             15000|\n",
      "|    max| Sunny|                31|               10|             30000|\n",
      "+-------+------+------------------+-----------------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_pyspark.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351c7f3c-2b1e-4087-b1fb-9e8543c61c26",
   "metadata": {},
   "source": [
    "### Adding columns in data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3ae0771b-cdd3-409d-bce5-1d3b76f36e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+------------------------+\n",
      "|     Name|age|Experience|Salary|Experience after 2 years|\n",
      "+---------+---+----------+------+------------------------+\n",
      "|    Krish| 31|        10| 30000|                      12|\n",
      "|Sudhanshu| 30|         8| 25000|                      10|\n",
      "|    Sunny| 29|         4| 20000|                       6|\n",
      "|     Paul| 24|         3| 20000|                       5|\n",
      "|   Harsha| 21|         1| 15000|                       3|\n",
      "|  Shubham| 23|         2| 18000|                       4|\n",
      "+---------+---+----------+------+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.withColumn('Experience after 2 years', df_pyspark['Experience'] + 2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ced22922-ec64-4c51-81c1-51ac7e4e6832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+------------------------+--------------------+\n",
      "|     Name|age|Experience|Salary|Experience after 2 years|Salary after 2 years|\n",
      "+---------+---+----------+------+------------------------+--------------------+\n",
      "|    Krish| 31|        10| 30000|                      12|             36000.0|\n",
      "|Sudhanshu| 30|         8| 25000|                      10|             30000.0|\n",
      "|    Sunny| 29|         4| 20000|                       6|             24000.0|\n",
      "|     Paul| 24|         3| 20000|                       5|             24000.0|\n",
      "|   Harsha| 21|         1| 15000|                       3|             18000.0|\n",
      "|  Shubham| 23|         2| 18000|                       4|             21600.0|\n",
      "+---------+---+----------+------+------------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.withColumns({'Experience after 2 years': df_pyspark['Experience']+2, 'Salary after 2 years': df_pyspark['Salary']*1.2}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "12341edd-eedd-4df6-82a3-868f090fe6b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+\n",
      "|     Naam|age|Experience|Salary|\n",
      "+---------+---+----------+------+\n",
      "|    Krish| 31|        10| 30000|\n",
      "|Sudhanshu| 30|         8| 25000|\n",
      "|    Sunny| 29|         4| 20000|\n",
      "|     Paul| 24|         3| 20000|\n",
      "|   Harsha| 21|         1| 15000|\n",
      "|  Shubham| 23|         2| 18000|\n",
      "+---------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.withColumnRenamed('Name', 'Naam').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a03fb0-a496-4cb0-a34d-bc5ca445f7f8",
   "metadata": {},
   "source": [
    "## Pyspark Part 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e16559a-2029-4aa5-be38-d7dd27157ff0",
   "metadata": {},
   "source": [
    "### Handling missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b5edb308-be91-4f20-81a3-4a2fce11bd1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+----------+------+\n",
      "|     Name| age|Experience|Salary|\n",
      "+---------+----+----------+------+\n",
      "|    Krish|  31|        10| 30000|\n",
      "|Sudhanshu|  30|         8| 25000|\n",
      "|    Sunny|  29|         4| 20000|\n",
      "|     Paul|  24|         3| 20000|\n",
      "|   Harsha|  21|         1| 15000|\n",
      "|  Shubham|  23|         2| 18000|\n",
      "|   Mahesh|null|      null| 40000|\n",
      "|     null|  34|        10| 38000|\n",
      "|     null|  36|      null|  null|\n",
      "+---------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark = spark.read.options(header ='true',inferschema = 'true').csv('../test2.csv')\n",
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "14ab7256-d176-4e54-9f44-ea4055b91e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- Experience: integer (nullable = true)\n",
      " |-- Salary: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7d20b99d-461d-4e64-9b8c-00a2682a9db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+----------+------+\n",
      "|     Name| age|Experience|Salary|\n",
      "+---------+----+----------+------+\n",
      "|    Krish|  31|        10| 30000|\n",
      "|Sudhanshu|  30|         8| 25000|\n",
      "|    Sunny|  29|         4| 20000|\n",
      "|     Paul|  24|         3| 20000|\n",
      "|   Harsha|  21|         1| 15000|\n",
      "|  Shubham|  23|         2| 18000|\n",
      "|   Mahesh|null|      null| 40000|\n",
      "|     null|  34|        10| 38000|\n",
      "|     null|  36|      null|  null|\n",
      "+---------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark = spark.read.options(inferschema = 'true', header = 'true').csv('../test2.csv')\n",
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e423fbcb-e915-4962-b685-a18a6addec57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- Experience: integer (nullable = true)\n",
      " |-- Salary: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e6734e1f-4ab6-4fbb-93cb-5cc600ad11dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+----------+------+\n",
      "|     Name| age|Experience|Salary|\n",
      "+---------+----+----------+------+\n",
      "|    Krish|  31|        10| 30000|\n",
      "|Sudhanshu|  30|         8| 25000|\n",
      "|    Sunny|  29|         4| 20000|\n",
      "|     Paul|  24|         3| 20000|\n",
      "|   Harsha|  21|         1| 15000|\n",
      "|  Shubham|  23|         2| 18000|\n",
      "|   Mahesh|null|      null| 40000|\n",
      "|     null|  34|        10| 38000|\n",
      "|     null|  36|      null|  null|\n",
      "+---------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark = spark.read.csv('../test2.csv', inferSchema = 'true', header = 'true')\n",
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a4cf5528-d7a1-428f-ae05-9865b51c8bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- Experience: integer (nullable = true)\n",
      " |-- Salary: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "79288077-2a95-4862-905b-c90ffabdb948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+------+\n",
      "|     Name|Experience|Salary|\n",
      "+---------+----------+------+\n",
      "|    Krish|        10| 30000|\n",
      "|Sudhanshu|         8| 25000|\n",
      "|    Sunny|         4| 20000|\n",
      "|     Paul|         3| 20000|\n",
      "|   Harsha|         1| 15000|\n",
      "|  Shubham|         2| 18000|\n",
      "|   Mahesh|      null| 40000|\n",
      "|     null|        10| 38000|\n",
      "|     null|      null|  null|\n",
      "+---------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.drop('age').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3e85213b-8e8b-49df-ba31-633da8fb2daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+\n",
      "|     Name|age|Experience|Salary|\n",
      "+---------+---+----------+------+\n",
      "|    Krish| 31|        10| 30000|\n",
      "|Sudhanshu| 30|         8| 25000|\n",
      "|    Sunny| 29|         4| 20000|\n",
      "|     Paul| 24|         3| 20000|\n",
      "|   Harsha| 21|         1| 15000|\n",
      "|  Shubham| 23|         2| 18000|\n",
      "+---------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.na.drop().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "77c511f9-04e3-4c17-8f4d-93912b3bd11b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+\n",
      "|     Name|age|Experience|Salary|\n",
      "+---------+---+----------+------+\n",
      "|    Krish| 31|        10| 30000|\n",
      "|Sudhanshu| 30|         8| 25000|\n",
      "|    Sunny| 29|         4| 20000|\n",
      "|     Paul| 24|         3| 20000|\n",
      "|   Harsha| 21|         1| 15000|\n",
      "|  Shubham| 23|         2| 18000|\n",
      "+---------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.na.drop(how = 'any').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2c5969e6-bf60-4432-ae3c-5edefa80bc5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+----------+------+\n",
      "|     Name| age|Experience|Salary|\n",
      "+---------+----+----------+------+\n",
      "|    Krish|  31|        10| 30000|\n",
      "|Sudhanshu|  30|         8| 25000|\n",
      "|    Sunny|  29|         4| 20000|\n",
      "|     Paul|  24|         3| 20000|\n",
      "|   Harsha|  21|         1| 15000|\n",
      "|  Shubham|  23|         2| 18000|\n",
      "|   Mahesh|null|      null| 40000|\n",
      "|     null|  34|        10| 38000|\n",
      "|     null|  36|      null|  null|\n",
      "+---------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.na.drop(how = 'all').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a912c9ca-5f18-458f-ba8a-b3266f890504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+\n",
      "|     Name|age|Experience|Salary|\n",
      "+---------+---+----------+------+\n",
      "|    Krish| 31|        10| 30000|\n",
      "|Sudhanshu| 30|         8| 25000|\n",
      "|    Sunny| 29|         4| 20000|\n",
      "|     Paul| 24|         3| 20000|\n",
      "|   Harsha| 21|         1| 15000|\n",
      "|  Shubham| 23|         2| 18000|\n",
      "|     null| 34|        10| 38000|\n",
      "+---------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.na.drop(how = 'any', thresh = 3).show() ## For cases where atleast 3 non null values are there will be reatained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ade9bfea-f438-4911-9d35-bccf697a7ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+----------+------+\n",
      "|     Name| age|Experience|Salary|\n",
      "+---------+----+----------+------+\n",
      "|    Krish|  31|        10| 30000|\n",
      "|Sudhanshu|  30|         8| 25000|\n",
      "|    Sunny|  29|         4| 20000|\n",
      "|     Paul|  24|         3| 20000|\n",
      "|   Harsha|  21|         1| 15000|\n",
      "|  Shubham|  23|         2| 18000|\n",
      "|   Mahesh|null|      null| 40000|\n",
      "|     null|  34|        10| 38000|\n",
      "+---------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.na.drop(how = 'any', thresh = 2).show() ## For cases where atleast 2 non null values are there will be reatained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cd516c22-1efc-487d-b290-f133c4b80464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+----------+------+\n",
      "|     Name| age|Experience|Salary|\n",
      "+---------+----+----------+------+\n",
      "|    Krish|  31|        10| 30000|\n",
      "|Sudhanshu|  30|         8| 25000|\n",
      "|    Sunny|  29|         4| 20000|\n",
      "|     Paul|  24|         3| 20000|\n",
      "|   Harsha|  21|         1| 15000|\n",
      "|  Shubham|  23|         2| 18000|\n",
      "|   Mahesh|null|      null| 40000|\n",
      "|     null|  34|        10| 38000|\n",
      "|     null|  36|      null|  null|\n",
      "+---------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.na.drop(how = 'any', thresh = 1).show() ## For cases where atleast 1 non null values are there will be reatained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e48e6ef4-5d38-4530-bee2-60ea2f0f3c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+\n",
      "|     Name|age|Experience|Salary|\n",
      "+---------+---+----------+------+\n",
      "|    Krish| 31|        10| 30000|\n",
      "|Sudhanshu| 30|         8| 25000|\n",
      "|    Sunny| 29|         4| 20000|\n",
      "|     Paul| 24|         3| 20000|\n",
      "|   Harsha| 21|         1| 15000|\n",
      "|  Shubham| 23|         2| 18000|\n",
      "|     null| 34|        10| 38000|\n",
      "|     null| 36|      null|  null|\n",
      "+---------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.na.drop(how = 'any', subset = 'age').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "45545ef5-93b8-4b85-b30a-20286a9e801e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+\n",
      "|     Name|age|Experience|Salary|\n",
      "+---------+---+----------+------+\n",
      "|    Krish| 31|        10| 30000|\n",
      "|Sudhanshu| 30|         8| 25000|\n",
      "|    Sunny| 29|         4| 20000|\n",
      "|     Paul| 24|         3| 20000|\n",
      "|   Harsha| 21|         1| 15000|\n",
      "|  Shubham| 23|         2| 18000|\n",
      "+---------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.na.drop(how = 'any', subset = ['age', 'Name']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "99eb3bfd-e744-4bac-a511-7d5455200034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+\n",
      "|     Name|age|Experience|Salary|\n",
      "+---------+---+----------+------+\n",
      "|    Krish| 31|        10| 30000|\n",
      "|Sudhanshu| 30|         8| 25000|\n",
      "|    Sunny| 29|         4| 20000|\n",
      "|     Paul| 24|         3| 20000|\n",
      "|   Harsha| 21|         1| 15000|\n",
      "|  Shubham| 23|         2| 18000|\n",
      "|     null| 34|        10| 38000|\n",
      "+---------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.na.drop(how = 'any', subset = ['age', 'Experience']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5ed83c3a-a3bb-4447-a6d4-f7653dcc0c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----+----------+------+\n",
      "|          Name| age|Experience|Salary|\n",
      "+--------------+----+----------+------+\n",
      "|         Krish|  31|        10| 30000|\n",
      "|     Sudhanshu|  30|         8| 25000|\n",
      "|         Sunny|  29|         4| 20000|\n",
      "|          Paul|  24|         3| 20000|\n",
      "|        Harsha|  21|         1| 15000|\n",
      "|       Shubham|  23|         2| 18000|\n",
      "|        Mahesh|null|      null| 40000|\n",
      "|Missing values|  34|        10| 38000|\n",
      "|Missing values|  36|      null|  null|\n",
      "+--------------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.na.fill('Missing values',subset='Name').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "cf810949-80f8-4b9a-a5f0-71e6bb51d95d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+----------+------+\n",
      "|     Name| age|Experience|Salary|\n",
      "+---------+----+----------+------+\n",
      "|    Krish|  31|        10| 30000|\n",
      "|Sudhanshu|  30|         8| 25000|\n",
      "|    Sunny|  29|         4| 20000|\n",
      "|     Paul|  24|         3| 20000|\n",
      "|   Harsha|  21|         1| 15000|\n",
      "|  Shubham|  23|         2| 18000|\n",
      "|   Mahesh|null|         0| 40000|\n",
      "|     null|  34|        10| 38000|\n",
      "|     null|  36|         0|     0|\n",
      "+---------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.na.fill(0, subset = ['salary','Experience']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e3973e35-4c6a-4c24-8fce-28ad93c418b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+----------+------+\n",
      "|     Name| age|Experience|Salary|\n",
      "+---------+----+----------+------+\n",
      "|    Krish|  31|        10| 30000|\n",
      "|Sudhanshu|  30|         8| 25000|\n",
      "|    Sunny|  29|         4| 20000|\n",
      "|     Paul|  24|         3| 20000|\n",
      "|   Harsha|  21|         1| 15000|\n",
      "|  Shubham|  23|         2| 18000|\n",
      "|   Mahesh|null|         0| 40000|\n",
      "|  Missing|  34|        10| 38000|\n",
      "|  Missing|  36|         0|     0|\n",
      "+---------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.na.fill('Missing').na.fill(0, subset = ['salary','Experience']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "62577b5d-f381-4883-9dcd-8b5a812f674c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+\n",
      "|     Name|age|Experience|Salary|\n",
      "+---------+---+----------+------+\n",
      "|    Krish| 31|        10| 30000|\n",
      "|Sudhanshu| 30|         8| 25000|\n",
      "|    Sunny| 29|         4| 20000|\n",
      "|     Paul| 24|         3| 20000|\n",
      "|   Harsha| 21|         1| 15000|\n",
      "|  Shubham| 23|         2| 18000|\n",
      "|   Mahesh|  0|         0| 40000|\n",
      "|  Missing| 34|        10| 38000|\n",
      "|  Missing| 36|         0|     0|\n",
      "+---------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.na.fill('Missing').na.fill(0).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0bdf5300-d3a7-40ef-bdfb-da38ce4f1d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+----------+------+\n",
      "|     Name| age|Experience|Salary|\n",
      "+---------+----+----------+------+\n",
      "|    Krish|  31|        10| 30000|\n",
      "|Sudhanshu|  30|         8| 25000|\n",
      "|    Sunny|  29|         4| 20000|\n",
      "|     Paul|  24|         3| 20000|\n",
      "|   Harsha|  21|         1| 15000|\n",
      "|  Shubham|  23|         2| 18000|\n",
      "|   Mahesh|null|         0| 40000|\n",
      "|  Missing|  34|        10| 38000|\n",
      "|  Missing|  36|         0|     0|\n",
      "+---------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.na.fill('Missing').na.fill(0,['salary','Experience']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5c6fdfa5-15a7-4930-a42a-e3306bf01449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+----------+------+\n",
      "|     Name| age|Experience|Salary|\n",
      "+---------+----+----------+------+\n",
      "|    Krish|  31|        10| 30000|\n",
      "|Sudhanshu|  30|         8| 25000|\n",
      "|    Sunny|  29|         4| 20000|\n",
      "|     Paul|  24|         3| 20000|\n",
      "|   Harsha|  21|         1| 15000|\n",
      "|  Shubham|  23|         2| 18000|\n",
      "|   Mahesh|null|         0| 40000|\n",
      "|     null|  34|        10| 38000|\n",
      "|     null|  36|         0|     0|\n",
      "+---------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.na.fill(0,['Experience','Salary']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3b65430c-e355-4c6f-846a-9c4d5506a087",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark = spark.read.csv('../test2.csv', header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6b0d4015-1e27-4df0-adfe-4f01f66daeb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+--------------+--------------+\n",
      "|     Name| age|    Experience|        Salary|\n",
      "+---------+----+--------------+--------------+\n",
      "|    Krish|  31|            10|         30000|\n",
      "|Sudhanshu|  30|             8|         25000|\n",
      "|    Sunny|  29|             4|         20000|\n",
      "|     Paul|  24|             3|         20000|\n",
      "|   Harsha|  21|             1|         15000|\n",
      "|  Shubham|  23|             2|         18000|\n",
      "|   Mahesh|null|Missing values|         40000|\n",
      "|     null|  34|            10|         38000|\n",
      "|     null|  36|Missing values|Missing values|\n",
      "+---------+----+--------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.na.fill('Missing values',['Experience','Salary']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64f9f06-d17d-4f89-9f13-7115f62853fd",
   "metadata": {},
   "source": [
    "### Using imputer to impute missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "1e8dce2f-a7a5-4585-95b0-f0205c044f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark = spark.read.option('inferschema', 'true').csv('../test2.csv', header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f80ebcd7-e474-471c-89ba-e0cd451142e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b5a2336c-f727-40eb-b045-39b308374ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = Imputer(\n",
    "    inputCols= ['age','Experience','Salary'],\n",
    "    outputCols= ['{}_col'.format(c) for c in ['age','Experience','Salary']],\n",
    "    strategy= 'mean'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "1d3600a1-9df1-4464-b6f6-109f3a32c6f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+----------+------+-------+--------------+----------+\n",
      "|     Name| age|Experience|Salary|age_col|Experience_col|Salary_col|\n",
      "+---------+----+----------+------+-------+--------------+----------+\n",
      "|    Krish|  31|        10| 30000|     31|            10|     30000|\n",
      "|Sudhanshu|  30|         8| 25000|     30|             8|     25000|\n",
      "|    Sunny|  29|         4| 20000|     29|             4|     20000|\n",
      "|     Paul|  24|         3| 20000|     24|             3|     20000|\n",
      "|   Harsha|  21|         1| 15000|     21|             1|     15000|\n",
      "|  Shubham|  23|         2| 18000|     23|             2|     18000|\n",
      "|   Mahesh|null|      null| 40000|     28|             5|     40000|\n",
      "|     null|  34|        10| 38000|     34|            10|     38000|\n",
      "|     null|  36|      null|  null|     36|             5|     25750|\n",
      "+---------+----+----------+------+-------+--------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add imputation cols to df\n",
    "imputer.fit(df_pyspark).transform(df_pyspark).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "76cda029-f4cc-4821-883d-776df558708a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------------------+------------------+-----------------+\n",
      "|summary|  Name|               age|        Experience|           Salary|\n",
      "+-------+------+------------------+------------------+-----------------+\n",
      "|  count|     7|                 8|                 7|                8|\n",
      "|   mean|  null|              28.5| 5.428571428571429|          25750.0|\n",
      "| stddev|  null|5.3718844791323335|3.8234863173611093|9361.776388210581|\n",
      "|    min|Harsha|                21|                 1|            15000|\n",
      "|    max| Sunny|                36|                10|            40000|\n",
      "+-------+------+------------------+------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a89a2cef-d189-4e3f-b9c6-96c2289f0a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|               age|\n",
      "+-------+------------------+\n",
      "|  count|                 8|\n",
      "|   mean|              28.5|\n",
      "| stddev|5.3718844791323335|\n",
      "|    min|                21|\n",
      "|    max|                36|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.describe('age').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "afdb4c8d-892e-4f38-ad28-d3614debb9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = Imputer(\n",
    "    inputCols= ['age','Experience','Salary'],\n",
    "    outputCols= ['{}_col'.format(c) for c in ['age','Experience','Salary']]\n",
    ").setStrategy('median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "68d5e32c-73dc-4b16-8215-403ef64fde9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+----------+------+-------+--------------+----------+\n",
      "|     Name| age|Experience|Salary|age_col|Experience_col|Salary_col|\n",
      "+---------+----+----------+------+-------+--------------+----------+\n",
      "|    Krish|  31|        10| 30000|     31|            10|     30000|\n",
      "|Sudhanshu|  30|         8| 25000|     30|             8|     25000|\n",
      "|    Sunny|  29|         4| 20000|     29|             4|     20000|\n",
      "|     Paul|  24|         3| 20000|     24|             3|     20000|\n",
      "|   Harsha|  21|         1| 15000|     21|             1|     15000|\n",
      "|  Shubham|  23|         2| 18000|     23|             2|     18000|\n",
      "|   Mahesh|null|      null| 40000|     29|             4|     40000|\n",
      "|     null|  34|        10| 38000|     34|            10|     38000|\n",
      "|     null|  36|      null|  null|     36|             4|     20000|\n",
      "+---------+----+----------+------+-------+--------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "imputer.fit(df_pyspark).transform(df_pyspark).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5187f246-6df3-4e69-ad81-a179a46b8345",
   "metadata": {},
   "source": [
    "## Pyspark Part 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4995bf96-95ae-4d1f-b6cb-3645c6a99282",
   "metadata": {},
   "source": [
    "### Filter operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "77c4e979-08d1-431d-ae0d-db3043bc071a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark = spark.read.csv('../test1.csv', inferSchema = True, header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e6725cd2-a231-4ed1-b70f-a8547260936f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+\n",
      "|     Name|age|Experience|Salary|\n",
      "+---------+---+----------+------+\n",
      "|    Krish| 31|        10| 30000|\n",
      "|Sudhanshu| 30|         8| 25000|\n",
      "|    Sunny| 29|         4| 20000|\n",
      "|     Paul| 24|         3| 20000|\n",
      "|   Harsha| 21|         1| 15000|\n",
      "|  Shubham| 23|         2| 18000|\n",
      "+---------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "4e86c89d-c342-4483-92e8-f6ad36b6df11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+\n",
      "|     Name|age|Experience|Salary|\n",
      "+---------+---+----------+------+\n",
      "|Sudhanshu| 30|         8| 25000|\n",
      "|    Sunny| 29|         4| 20000|\n",
      "|     Paul| 24|         3| 20000|\n",
      "|   Harsha| 21|         1| 15000|\n",
      "|  Shubham| 23|         2| 18000|\n",
      "+---------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.filter(df_pyspark['Experience']< 10 ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "bdfbade3-2a2f-4bf2-84ae-6241a2b3d7e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+\n",
      "|     Name|age|Experience|Salary|\n",
      "+---------+---+----------+------+\n",
      "|Sudhanshu| 30|         8| 25000|\n",
      "|    Sunny| 29|         4| 20000|\n",
      "|     Paul| 24|         3| 20000|\n",
      "|   Harsha| 21|         1| 15000|\n",
      "|  Shubham| 23|         2| 18000|\n",
      "+---------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.filter('Experience < 10' ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "5d4e41a5-9b3b-450e-bbc0-fc56a22867f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+\n",
      "|     Name|age|\n",
      "+---------+---+\n",
      "|    Krish| 31|\n",
      "|Sudhanshu| 30|\n",
      "|    Sunny| 29|\n",
      "+---------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.filter('Experience > 3').select(['Name','age']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "6d33923b-6abc-42bb-83f5-0d25687fabc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+----------+------+\n",
      "| Name|age|Experience|Salary|\n",
      "+-----+---+----------+------+\n",
      "|Sunny| 29|         4| 20000|\n",
      "+-----+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.filter((df_pyspark['Experience'] > 3) & (df_pyspark['age'] < 30)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "12b936b4-93a9-4a04-84a0-84f5e02fc5a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+\n",
      "|     Name|age|Experience|Salary|\n",
      "+---------+---+----------+------+\n",
      "|    Krish| 31|        10| 30000|\n",
      "|Sudhanshu| 30|         8| 25000|\n",
      "|    Sunny| 29|         4| 20000|\n",
      "|     Paul| 24|         3| 20000|\n",
      "|   Harsha| 21|         1| 15000|\n",
      "|  Shubham| 23|         2| 18000|\n",
      "+---------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.filter((df_pyspark['Experience'] > 3) | (df_pyspark['age'] < 30)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "fdb9bdc4-84ba-4667-a2ea-5ce5e6edaf2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----------+------+\n",
      "|   Name|age|Experience|Salary|\n",
      "+-------+---+----------+------+\n",
      "|   Paul| 24|         3| 20000|\n",
      "| Harsha| 21|         1| 15000|\n",
      "|Shubham| 23|         2| 18000|\n",
      "+-------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.filter(~(df_pyspark['Experience'] > 3)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f4f528-b682-4e48-a6d0-95b738f737e5",
   "metadata": {},
   "source": [
    "## Pyspark Part 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6dbfc7-a446-4128-86c7-e0f8695969d7",
   "metadata": {},
   "source": [
    "### Group by and aggregate functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "926534b9-c660-4723-a97f-d908a8f90c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------+------+\n",
      "|     Name| Departments|salary|\n",
      "+---------+------------+------+\n",
      "|    Krish|Data Science| 10000|\n",
      "|    Krish|         IOT|  5000|\n",
      "|   Mahesh|    Big Data|  4000|\n",
      "|    Krish|    Big Data|  4000|\n",
      "|   Mahesh|Data Science|  3000|\n",
      "|Sudhanshu|Data Science| 20000|\n",
      "|Sudhanshu|         IOT| 10000|\n",
      "|Sudhanshu|    Big Data|  5000|\n",
      "|    Sunny|Data Science| 10000|\n",
      "|    Sunny|    Big Data|  2000|\n",
      "+---------+------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark = spark.read.csv('../test3.csv', inferSchema=True, header = True)\n",
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "aa71263a-527e-4a15-a1d4-dde2af52b42c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Departments: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "b8c8bf12-db0b-4dfa-b917-b7a1449b4459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+\n",
      "|     Name|sum(salary)|\n",
      "+---------+-----------+\n",
      "|Sudhanshu|      35000|\n",
      "|    Sunny|      12000|\n",
      "|    Krish|      19000|\n",
      "|   Mahesh|       7000|\n",
      "+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.groupBy('Name').sum().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "1893b1ba-e82b-4b6a-b2e3-871cda098b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+\n",
      "|     Name|       avg(salary)|\n",
      "+---------+------------------+\n",
      "|Sudhanshu|11666.666666666666|\n",
      "|    Sunny|            6000.0|\n",
      "|    Krish| 6333.333333333333|\n",
      "|   Mahesh|            3500.0|\n",
      "+---------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.groupBy('Name').mean().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "ed9ad1d9-19ab-4b6c-a3d1-b618b496b982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+\n",
      "|     Name|       avg(salary)|\n",
      "+---------+------------------+\n",
      "|Sudhanshu|11666.666666666666|\n",
      "|    Sunny|            6000.0|\n",
      "|    Krish| 6333.333333333333|\n",
      "|   Mahesh|            3500.0|\n",
      "+---------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.groupBy('Name').avg().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "3b27e9c9-dc62-43a0-9991-8010b1fb42cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|     Name|count|\n",
      "+---------+-----+\n",
      "|Sudhanshu|    3|\n",
      "|    Sunny|    2|\n",
      "|    Krish|    3|\n",
      "|   Mahesh|    2|\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.groupBy('Name').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "ddaf6252-d58d-4fab-91e8-19f8e03e60f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "| Departments|count|\n",
      "+------------+-----+\n",
      "|         IOT|    2|\n",
      "|    Big Data|    4|\n",
      "|Data Science|    4|\n",
      "+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.groupBy('Departments').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "798e41db-768c-4b0a-b373-1097c24ef242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+\n",
      "| Departments|avg(salary)|\n",
      "+------------+-----------+\n",
      "|         IOT|     7500.0|\n",
      "|    Big Data|     3750.0|\n",
      "|Data Science|    10750.0|\n",
      "+------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.groupBy('Departments').avg().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "e88d1ebe-8a43-46ee-9090-f65857520382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+\n",
      "| Departments|sum(salary)|\n",
      "+------------+-----------+\n",
      "|         IOT|      15000|\n",
      "|    Big Data|      15000|\n",
      "|Data Science|      43000|\n",
      "+------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.groupBy('Departments').sum().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "a66b3970-4595-476f-a132-8f50b1524ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+\n",
      "| Departments|max(salary)|\n",
      "+------------+-----------+\n",
      "|         IOT|      10000|\n",
      "|    Big Data|       5000|\n",
      "|Data Science|      20000|\n",
      "+------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.groupBy('Departments').max().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "4467bc57-75d2-4ee3-85db-8246af61f1bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+\n",
      "|     Name|max(salary)|\n",
      "+---------+-----------+\n",
      "|Sudhanshu|      20000|\n",
      "|    Sunny|      10000|\n",
      "|    Krish|      10000|\n",
      "|   Mahesh|       4000|\n",
      "+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.groupBy('Name').max().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "bd83c2d0-5458-46a5-ba45-daf2ca4b66d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|sum(Salary)|\n",
      "+-----------+\n",
      "|      73000|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.agg({'Salary':'sum'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "765885d9-312a-438c-80c3-773be15e9103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------+------+\n",
      "|     Name| Departments|salary|\n",
      "+---------+------------+------+\n",
      "|    Krish|Data Science| 10000|\n",
      "|    Krish|         IOT|  5000|\n",
      "|   Mahesh|    Big Data|  4000|\n",
      "|    Krish|    Big Data|  4000|\n",
      "|   Mahesh|Data Science|  3000|\n",
      "|Sudhanshu|Data Science| 20000|\n",
      "|Sudhanshu|         IOT| 10000|\n",
      "|Sudhanshu|    Big Data|  5000|\n",
      "|    Sunny|Data Science| 10000|\n",
      "|    Sunny|    Big Data|  2000|\n",
      "+---------+------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "034bce50-deb2-4bd6-8c72-95533d654aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|median(Salary)|\n",
      "+--------------+\n",
      "|        5000.0|\n",
      "+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.agg({'Salary':'median'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "3ff5ee5a-cf29-4b5a-aaaa-a1a241ea8dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------+------+\n",
      "|     Name| Departments|salary|\n",
      "+---------+------------+------+\n",
      "|Sudhanshu|Data Science| 20000|\n",
      "|    Krish|Data Science| 10000|\n",
      "|Sudhanshu|         IOT| 10000|\n",
      "|    Sunny|Data Science| 10000|\n",
      "|    Krish|         IOT|  5000|\n",
      "|Sudhanshu|    Big Data|  5000|\n",
      "|   Mahesh|    Big Data|  4000|\n",
      "|    Krish|    Big Data|  4000|\n",
      "|   Mahesh|Data Science|  3000|\n",
      "|    Sunny|    Big Data|  2000|\n",
      "+---------+------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.sort('Salary', ascending = False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "52b16c81-f07b-41b8-ab4f-6bc51e3fb18a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|   stddev(Salary)|\n",
      "+-----------------+\n",
      "|5396.500923952689|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.agg({'Salary':'stddev'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "2b5b956f-566b-42ee-8fa3-692d3aa1fd04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|avg(Salary)|\n",
      "+-----------+\n",
      "|     7300.0|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.agg({'Salary':'mean'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "aa69eae0-67b0-4c47-8ec7-da8366b433bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+-----------+-----------------+\n",
      "|summary| Name|Departments|           salary|\n",
      "+-------+-----+-----------+-----------------+\n",
      "|  count|   10|         10|               10|\n",
      "|   mean| null|       null|           7300.0|\n",
      "| stddev| null|       null|5396.500923952689|\n",
      "|    min|Krish|   Big Data|             2000|\n",
      "|    max|Sunny|        IOT|            20000|\n",
      "+-------+-----+-----------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aace03e6-9b50-4db0-a469-8ef3bcaedcaf",
   "metadata": {},
   "source": [
    "## Part 6 Pyspark ML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ef21cf-9028-471d-bcb6-0a8c02be82e5",
   "metadata": {},
   "source": [
    "### Examples of Pyspark ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "e8913a1e-2cb2-4d4a-8c7e-e04dd29bfd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read The dataset\n",
    "training = spark.read.csv('../test1.csv',header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "6568b0f2-e672-4f9a-b798-cb637ebdf960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+\n",
      "|     Name|age|Experience|Salary|\n",
      "+---------+---+----------+------+\n",
      "|    Krish| 31|        10| 30000|\n",
      "|Sudhanshu| 30|         8| 25000|\n",
      "|    Sunny| 29|         4| 20000|\n",
      "|     Paul| 24|         3| 20000|\n",
      "|   Harsha| 21|         1| 15000|\n",
      "|  Shubham| 23|         2| 18000|\n",
      "+---------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c84718a-1077-42ba-a75f-b4fad0fc3c96",
   "metadata": {},
   "source": [
    "### Using Vector Assembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "ba44eee6-606b-4434-9042-04ab4d250c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+\n",
      "|     Name|age|Experience|Salary|\n",
      "+---------+---+----------+------+\n",
      "|    Krish| 31|        10| 30000|\n",
      "|Sudhanshu| 30|         8| 25000|\n",
      "|    Sunny| 29|         4| 20000|\n",
      "|     Paul| 24|         3| 20000|\n",
      "|   Harsha| 21|         1| 15000|\n",
      "|  Shubham| 23|         2| 18000|\n",
      "+---------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "91b810e5-d8af-41ee-ad7a-b09998f81af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "57191532-c42d-42fc-961a-d3ca789dd2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "featureassembler = VectorAssembler(inputCols = ['age', 'Experience'], outputCol = 'Independent variables')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "5853a5fb-e9dd-48b1-9325-a7bace376f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = featureassembler.transform(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "28e2ebee-dbaa-4e7f-bc5f-3777d3c38ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+---------------------+\n",
      "|     Name|age|Experience|Salary|Independent variables|\n",
      "+---------+---+----------+------+---------------------+\n",
      "|    Krish| 31|        10| 30000|          [31.0,10.0]|\n",
      "|Sudhanshu| 30|         8| 25000|           [30.0,8.0]|\n",
      "|    Sunny| 29|         4| 20000|           [29.0,4.0]|\n",
      "|     Paul| 24|         3| 20000|           [24.0,3.0]|\n",
      "|   Harsha| 21|         1| 15000|           [21.0,1.0]|\n",
      "|  Shubham| 23|         2| 18000|           [23.0,2.0]|\n",
      "+---------+---+----------+------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "2980d63a-0695-45d3-a306-961e0ef2af3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+------+\n",
      "|Independent variables|Salary|\n",
      "+---------------------+------+\n",
      "|          [31.0,10.0]| 30000|\n",
      "|           [30.0,8.0]| 25000|\n",
      "|           [29.0,4.0]| 20000|\n",
      "|           [24.0,3.0]| 20000|\n",
      "|           [21.0,1.0]| 15000|\n",
      "|           [23.0,2.0]| 18000|\n",
      "+---------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "finalized_data = output.select(['Independent variables', 'Salary'])\n",
    "finalized_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "f4cd365b-e98f-4feb-96d0-ba56ee42cb7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/07/31 12:14:45 WARN Instrumentation: [854b892f] regParam is zero, which might cause numerical instability and overfitting.\n",
      "23/07/31 12:14:45 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "23/07/31 12:14:45 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.lapack.JNILAPACK\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "## Train test split\n",
    "train_data , test_data = finalized_data.randomSplit([0.75,0.25])\n",
    "linear_regression = LinearRegression(featuresCol= 'Independent variables', labelCol='Salary')\n",
    "linear_regression = linear_regression.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "996a8f20-232f-4222-852d-ef46e99b7f2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([-90.5483, 1608.7819])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_regression.coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "97c286a3-88a4-410f-8c4b-b4dec885f28a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16079.136690647425"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_regression.intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "34162e9a-b526-436d-aa51-7f0ab7e9b14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prediction\n",
    "pred_results=linear_regression.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "c7506555-090a-45f7-8514-a8e748642f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+------+-----------------+\n",
      "|Independent variables|Salary|       prediction|\n",
      "+---------------------+------+-----------------+\n",
      "|           [23.0,2.0]| 18000|17214.09079632846|\n",
      "+---------------------+------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_results.predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "2589c75c-38c0-4850-bedb-dfa31a179d12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(785.909203671541, 617653.2764156357)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_results.meanAbsoluteError,pred_results.meanSquaredError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f501ba68-f8cc-45a1-999b-1f1a65c01f2e",
   "metadata": {},
   "source": [
    "## Pyspark Part 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "10f91ff6-a037-4561-a564-56e383462556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|\n",
      "+----------+----+------+------+---+------+----+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|\n",
      "|     25.29|4.71|  Male|    No|Sun|Dinner|   4|\n",
      "|      8.77| 2.0|  Male|    No|Sun|Dinner|   2|\n",
      "|     26.88|3.12|  Male|    No|Sun|Dinner|   4|\n",
      "|     15.04|1.96|  Male|    No|Sun|Dinner|   2|\n",
      "|     14.78|3.23|  Male|    No|Sun|Dinner|   2|\n",
      "|     10.27|1.71|  Male|    No|Sun|Dinner|   2|\n",
      "|     35.26| 5.0|Female|    No|Sun|Dinner|   4|\n",
      "|     15.42|1.57|  Male|    No|Sun|Dinner|   2|\n",
      "|     18.43| 3.0|  Male|    No|Sun|Dinner|   4|\n",
      "|     14.83|3.02|Female|    No|Sun|Dinner|   2|\n",
      "|     21.58|3.92|  Male|    No|Sun|Dinner|   2|\n",
      "|     10.33|1.67|Female|    No|Sun|Dinner|   3|\n",
      "|     16.29|3.71|  Male|    No|Sun|Dinner|   3|\n",
      "|     16.97| 3.5|Female|    No|Sun|Dinner|   3|\n",
      "|     20.65|3.35|  Male|    No|Sat|Dinner|   3|\n",
      "+----------+----+------+------+---+------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv('../tips.csv', inferSchema=True, header=True)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "e268ab9a-ae83-4b56-87e3-abb026b99a25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['total_bill', 'tip', 'sex', 'smoker', 'day', 'time', 'size']"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "e4dc80c9-78e5-4a29-ab99-752e0c287a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Handling Categorical Features\n",
    "from pyspark.ml.feature import StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "feda8df3-555d-49c1-849e-7eaf4d10ea67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+-----------+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|sex_indexed|\n",
      "+----------+----+------+------+---+------+----+-----------+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|        1.0|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|        0.0|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|        0.0|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2|        0.0|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|        1.0|\n",
      "|     25.29|4.71|  Male|    No|Sun|Dinner|   4|        0.0|\n",
      "|      8.77| 2.0|  Male|    No|Sun|Dinner|   2|        0.0|\n",
      "|     26.88|3.12|  Male|    No|Sun|Dinner|   4|        0.0|\n",
      "|     15.04|1.96|  Male|    No|Sun|Dinner|   2|        0.0|\n",
      "|     14.78|3.23|  Male|    No|Sun|Dinner|   2|        0.0|\n",
      "|     10.27|1.71|  Male|    No|Sun|Dinner|   2|        0.0|\n",
      "|     35.26| 5.0|Female|    No|Sun|Dinner|   4|        1.0|\n",
      "|     15.42|1.57|  Male|    No|Sun|Dinner|   2|        0.0|\n",
      "|     18.43| 3.0|  Male|    No|Sun|Dinner|   4|        0.0|\n",
      "|     14.83|3.02|Female|    No|Sun|Dinner|   2|        1.0|\n",
      "|     21.58|3.92|  Male|    No|Sun|Dinner|   2|        0.0|\n",
      "|     10.33|1.67|Female|    No|Sun|Dinner|   3|        1.0|\n",
      "|     16.29|3.71|  Male|    No|Sun|Dinner|   3|        0.0|\n",
      "|     16.97| 3.5|Female|    No|Sun|Dinner|   3|        1.0|\n",
      "|     20.65|3.35|  Male|    No|Sat|Dinner|   3|        0.0|\n",
      "+----------+----+------+------+---+------+----+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "indexer = StringIndexer(inputCol = 'sex', outputCol= 'sex_indexed')\n",
    "# df_r = \n",
    "indexer.fit(df).transform(df).show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "39c715d6-5998-44ef-ad29-e0047d9b49eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_r = indexer.fit(df).transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "8e90148c-6d27-404c-9a6f-ffcb49c3f10b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+-----------+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|sex_indexed|\n",
      "+----------+----+------+------+---+------+----+-----------+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|        1.0|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|        0.0|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|        0.0|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2|        0.0|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|        1.0|\n",
      "|     25.29|4.71|  Male|    No|Sun|Dinner|   4|        0.0|\n",
      "|      8.77| 2.0|  Male|    No|Sun|Dinner|   2|        0.0|\n",
      "|     26.88|3.12|  Male|    No|Sun|Dinner|   4|        0.0|\n",
      "|     15.04|1.96|  Male|    No|Sun|Dinner|   2|        0.0|\n",
      "|     14.78|3.23|  Male|    No|Sun|Dinner|   2|        0.0|\n",
      "|     10.27|1.71|  Male|    No|Sun|Dinner|   2|        0.0|\n",
      "|     35.26| 5.0|Female|    No|Sun|Dinner|   4|        1.0|\n",
      "|     15.42|1.57|  Male|    No|Sun|Dinner|   2|        0.0|\n",
      "|     18.43| 3.0|  Male|    No|Sun|Dinner|   4|        0.0|\n",
      "|     14.83|3.02|Female|    No|Sun|Dinner|   2|        1.0|\n",
      "|     21.58|3.92|  Male|    No|Sun|Dinner|   2|        0.0|\n",
      "|     10.33|1.67|Female|    No|Sun|Dinner|   3|        1.0|\n",
      "|     16.29|3.71|  Male|    No|Sun|Dinner|   3|        0.0|\n",
      "|     16.97| 3.5|Female|    No|Sun|Dinner|   3|        1.0|\n",
      "|     20.65|3.35|  Male|    No|Sat|Dinner|   3|        0.0|\n",
      "+----------+----+------+------+---+------+----+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_r.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "9c82c360-5f16-4114-a58d-a8683fd42e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer = StringIndexer(inputCols= ['smoker','day','time'], outputCols=['{}_indexed'.format(c) for c in ['smoker','day','time']])\n",
    "df_r = indexer.fit(df_r).transform(df_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "e39aeca0-0874-4b8b-995d-dc1ec24a0a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+-----------+--------------+-----------+------------+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|sex_indexed|smoker_indexed|day_indexed|time_indexed|\n",
      "+----------+----+------+------+---+------+----+-----------+--------------+-----------+------------+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|        1.0|           0.0|        1.0|         0.0|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|        0.0|           0.0|        1.0|         0.0|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|        0.0|           0.0|        1.0|         0.0|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2|        0.0|           0.0|        1.0|         0.0|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|        1.0|           0.0|        1.0|         0.0|\n",
      "+----------+----+------+------+---+------+----+-----------+--------------+-----------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_r.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "5815ef58-d446-437f-8587-a9c4fd3c250a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['total_bill',\n",
       " 'tip',\n",
       " 'sex',\n",
       " 'smoker',\n",
       " 'day',\n",
       " 'time',\n",
       " 'size',\n",
       " 'sex_indexed',\n",
       " 'smoker_indexed',\n",
       " 'day_indexed',\n",
       " 'time_indexed']"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_r.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "327e0e18-4e10-4b1c-9a9e-a5b04ce2f5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "assembler = VectorAssembler(inputCols=['total_bill', 'size', 'sex_indexed', 'smoker_indexed', 'day_indexed', 'time_indexed'],\n",
    "                            outputCol = 'Independent Features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "cf219984-d1c2-4982-b0cd-a44cb41b8308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+-----------+--------------+-----------+------------+--------------------+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|sex_indexed|smoker_indexed|day_indexed|time_indexed|Independent Features|\n",
      "+----------+----+------+------+---+------+----+-----------+--------------+-----------+------------+--------------------+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|        1.0|           0.0|        1.0|         0.0|[16.99,2.0,1.0,0....|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|        0.0|           0.0|        1.0|         0.0|[10.34,3.0,0.0,0....|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|        0.0|           0.0|        1.0|         0.0|[21.01,3.0,0.0,0....|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2|        0.0|           0.0|        1.0|         0.0|[23.68,2.0,0.0,0....|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|        1.0|           0.0|        1.0|         0.0|[24.59,4.0,1.0,0....|\n",
      "|     25.29|4.71|  Male|    No|Sun|Dinner|   4|        0.0|           0.0|        1.0|         0.0|[25.29,4.0,0.0,0....|\n",
      "|      8.77| 2.0|  Male|    No|Sun|Dinner|   2|        0.0|           0.0|        1.0|         0.0|[8.77,2.0,0.0,0.0...|\n",
      "|     26.88|3.12|  Male|    No|Sun|Dinner|   4|        0.0|           0.0|        1.0|         0.0|[26.88,4.0,0.0,0....|\n",
      "|     15.04|1.96|  Male|    No|Sun|Dinner|   2|        0.0|           0.0|        1.0|         0.0|[15.04,2.0,0.0,0....|\n",
      "|     14.78|3.23|  Male|    No|Sun|Dinner|   2|        0.0|           0.0|        1.0|         0.0|[14.78,2.0,0.0,0....|\n",
      "|     10.27|1.71|  Male|    No|Sun|Dinner|   2|        0.0|           0.0|        1.0|         0.0|[10.27,2.0,0.0,0....|\n",
      "|     35.26| 5.0|Female|    No|Sun|Dinner|   4|        1.0|           0.0|        1.0|         0.0|[35.26,4.0,1.0,0....|\n",
      "|     15.42|1.57|  Male|    No|Sun|Dinner|   2|        0.0|           0.0|        1.0|         0.0|[15.42,2.0,0.0,0....|\n",
      "|     18.43| 3.0|  Male|    No|Sun|Dinner|   4|        0.0|           0.0|        1.0|         0.0|[18.43,4.0,0.0,0....|\n",
      "|     14.83|3.02|Female|    No|Sun|Dinner|   2|        1.0|           0.0|        1.0|         0.0|[14.83,2.0,1.0,0....|\n",
      "|     21.58|3.92|  Male|    No|Sun|Dinner|   2|        0.0|           0.0|        1.0|         0.0|[21.58,2.0,0.0,0....|\n",
      "|     10.33|1.67|Female|    No|Sun|Dinner|   3|        1.0|           0.0|        1.0|         0.0|[10.33,3.0,1.0,0....|\n",
      "|     16.29|3.71|  Male|    No|Sun|Dinner|   3|        0.0|           0.0|        1.0|         0.0|[16.29,3.0,0.0,0....|\n",
      "|     16.97| 3.5|Female|    No|Sun|Dinner|   3|        1.0|           0.0|        1.0|         0.0|[16.97,3.0,1.0,0....|\n",
      "|     20.65|3.35|  Male|    No|Sat|Dinner|   3|        0.0|           0.0|        0.0|         0.0|(6,[0,1],[20.65,3...|\n",
      "+----------+----+------+------+---+------+----+-----------+--------------+-----------+------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output = assembler.transform(df_r)\n",
    "output.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "15470361-d6d5-4b29-8f4c-95c1f93488ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|Independent Features|\n",
      "+--------------------+\n",
      "|[16.99,2.0,1.0,0....|\n",
      "|[10.34,3.0,0.0,0....|\n",
      "|[21.01,3.0,0.0,0....|\n",
      "|[23.68,2.0,0.0,0....|\n",
      "|[24.59,4.0,1.0,0....|\n",
      "|[25.29,4.0,0.0,0....|\n",
      "|[8.77,2.0,0.0,0.0...|\n",
      "|[26.88,4.0,0.0,0....|\n",
      "|[15.04,2.0,0.0,0....|\n",
      "|[14.78,2.0,0.0,0....|\n",
      "|[10.27,2.0,0.0,0....|\n",
      "|[35.26,4.0,1.0,0....|\n",
      "|[15.42,2.0,0.0,0....|\n",
      "|[18.43,4.0,0.0,0....|\n",
      "|[14.83,2.0,1.0,0....|\n",
      "|[21.58,2.0,0.0,0....|\n",
      "|[10.33,3.0,1.0,0....|\n",
      "|[16.29,3.0,0.0,0....|\n",
      "|[16.97,3.0,1.0,0....|\n",
      "|(6,[0,1],[20.65,3...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output.select('Independent Features').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "733ed5af-be3f-41ef-8fc5-b0202cd34a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+\n",
      "|Independent Features| tip|\n",
      "+--------------------+----+\n",
      "|[16.99,2.0,1.0,0....|1.01|\n",
      "|[10.34,3.0,0.0,0....|1.66|\n",
      "|[21.01,3.0,0.0,0....| 3.5|\n",
      "|[23.68,2.0,0.0,0....|3.31|\n",
      "|[24.59,4.0,1.0,0....|3.61|\n",
      "|[25.29,4.0,0.0,0....|4.71|\n",
      "|[8.77,2.0,0.0,0.0...| 2.0|\n",
      "|[26.88,4.0,0.0,0....|3.12|\n",
      "|[15.04,2.0,0.0,0....|1.96|\n",
      "|[14.78,2.0,0.0,0....|3.23|\n",
      "|[10.27,2.0,0.0,0....|1.71|\n",
      "|[35.26,4.0,1.0,0....| 5.0|\n",
      "|[15.42,2.0,0.0,0....|1.57|\n",
      "|[18.43,4.0,0.0,0....| 3.0|\n",
      "|[14.83,2.0,1.0,0....|3.02|\n",
      "|[21.58,2.0,0.0,0....|3.92|\n",
      "|[10.33,3.0,1.0,0....|1.67|\n",
      "|[16.29,3.0,0.0,0....|3.71|\n",
      "|[16.97,3.0,1.0,0....| 3.5|\n",
      "|(6,[0,1],[20.65,3...|3.35|\n",
      "+--------------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "finalized_data = output.select('Independent Features', 'tip')\n",
    "finalized_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "b05b43a0-e1c2-40c1-acd0-146e92928c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+\n",
      "|Independent Features| tip|\n",
      "+--------------------+----+\n",
      "|(6,[0,1],[9.55,2.0])|1.45|\n",
      "|(6,[0,1],[10.51,2...|1.25|\n",
      "|(6,[0,1],[12.02,2...|1.97|\n",
      "|(6,[0,1],[12.69,2...| 2.0|\n",
      "|(6,[0,1],[13.28,2...|2.72|\n",
      "+--------------------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train test split\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "train_data, test_data = finalized_data.randomSplit([0.75, 0.25])\n",
    "train_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "7c772879-98b3-4074-bb38-0ce898a07d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/07/31 12:46:12 WARN Instrumentation: [6b337c7a] regParam is zero, which might cause numerical instability and overfitting.\n"
     ]
    }
   ],
   "source": [
    "regressor = LinearRegression(featuresCol='Independent Features' ,labelCol= 'tip')\n",
    "regressor = regressor.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "9b6e735c-e9fe-4b77-92d4-83bbe03e3d4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([0.0846, 0.259, 0.1048, -0.2639, 0.1106, -0.0793])"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "bba4b99b-6095-4a60-bfb8-affd9973ac83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5259924328512966"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "90c50b6a-5136-43ec-b02a-9c9d2b5c7506",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predictions\n",
    "pred_results = regressor.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "6868a263-5df2-47a6-8de6-59d7486ddf5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+------------------+\n",
      "|Independent Features| tip|        prediction|\n",
      "+--------------------+----+------------------+\n",
      "|(6,[0,1],[10.07,2...|1.25|1.8959600776065515|\n",
      "|(6,[0,1],[10.77,2...|1.47|1.9551812899749916|\n",
      "|(6,[0,1],[11.61,2...|3.39|2.0262467448171195|\n",
      "|(6,[0,1],[13.37,2...| 2.0|2.1751457930577685|\n",
      "|(6,[0,1],[14.0,2.0])| 3.0| 2.228444884189365|\n",
      "|(6,[0,1],[17.81,4...|2.34| 3.068805686906856|\n",
      "|(6,[0,1],[17.92,2...|4.08| 2.560083673452629|\n",
      "|(6,[0,1],[20.08,3...|3.15|3.0018375164598776|\n",
      "|(6,[0,1],[21.7,2.0])| 4.3|2.8798782202422046|\n",
      "|(6,[0,1],[29.03,3...|5.92|3.7590230174563604|\n",
      "|(6,[0,1],[48.27,4...|6.73| 5.645774442253545|\n",
      "|[7.25,2.0,0.0,1.0...|5.15|1.5040948684431161|\n",
      "|[7.51,2.0,0.0,0.0...| 2.0|1.8213165024695182|\n",
      "|[8.58,1.0,0.0,1.0...|1.92|1.4995379286260653|\n",
      "|[10.33,3.0,1.0,0....|1.67|2.3923469108181363|\n",
      "|[11.17,2.0,1.0,0....| 1.5|2.2357153796966105|\n",
      "|[11.24,2.0,0.0,1....|1.76|1.7310360362966575|\n",
      "|[11.35,2.0,1.0,1....| 2.5| 2.176957993023504|\n",
      "|[11.59,2.0,0.0,1....| 1.5|1.7606466424808773|\n",
      "|[11.69,2.0,0.0,0....|2.31|  2.17495174204106|\n",
      "+--------------------+----+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_results.predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "af079e0e-3a93-40ae-9ece-2d027c1c67e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3789598349999539, 0.8982608566010509, 1.5796298027410625)"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Performance metrices\n",
    "pred_results.r2, pred_results.meanAbsoluteError, pred_results.meanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fb087f-38a2-4e92-b150-d3fcec216ee9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
